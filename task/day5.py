'''
    Day 5 è§†é¢‘è§‚çœ‹ï¼š
    8ï¼‰ä½¿ç”¨çˆ¬è™«çˆ¬å–å›¾ç‰‡é“¾æ¥å¹¶ä¸‹è½½å›¾ç‰‡

    ğŸ’¯Day 5 ä½œä¸šï¼š
    å­¦ä¹ å¼‚å¸¸å¤„ç†å¯¹ç½‘ç»œè¶…æ—¶ã€æ–‡ä»¶ä¸å­˜åœ¨ç­‰å¼‚å¸¸è¿›è¡Œæ•è·å¹¶å¤„ç†ã€‚

    å‚è€ƒèµ„æ–™ï¼š
    é”™è¯¯å’Œå¼‚å¸¸ï¼šhttps://docs.python.org/zh-cn/3/tutorial/errors.html

'''

from bs4 import BeautifulSoup
import requests
import os
import shutil

url = 'https://book.douban.com/top250'
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:70.0) Gecko/20100101 Firefox/70.0"
}

def download_jpg(image_url, image_localpath):
    response = requests.get(image_url, stream=True)
    if response.status_code == 200:
        with open(image_localpath, 'wb') as f:
            response.raw.deconde_content = True
            shutil.copyfileobj(response.raw, f)

#å–å¾—å›¾ç‰‡
def craw3(url):
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'lxml')
    # print(soup.prettify())
    for pic_href in soup.find_all('a', class_='nbg'):
        for pic in pic_href.find_all('img'):
            imgurl = pic.get('src')
            if imgurl is not None:
                dir = os.path.abspath('../img/')
                filename = os.path.basename(imgurl)
                imgpath = os.path.join(dir, filename)
                print('å¼€å§‹ä¸‹è½½: imgurl is %s, imgpath is %s' % (imgurl, imgpath))
                download_jpg(imgurl, imgpath)
craw3(url)